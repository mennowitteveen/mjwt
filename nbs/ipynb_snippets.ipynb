{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92653ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a7c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa95de26",
   "metadata": {},
   "source": [
    "# ipynb_snippets\n",
    "> This notebook & webpage (depending on how you're access it) contains a quick reference for python code to do various things. See the legend on the right to jump to a section.\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff64c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6da4ea43",
   "metadata": {},
   "source": [
    "# Some brief notes:\n",
    "\n",
    "- [Hamel's blog for inspiration](https://hamel.dev/notes/linux/bash_scripting.html)\n",
    "- some person's homepage https://www.mm218.dev/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb10c118",
   "metadata": {},
   "source": [
    "Oke this is a bunch of test text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb6949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94da41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8bb0d3f",
   "metadata": {},
   "source": [
    "# Todo dump:\n",
    "\n",
    "- pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b49a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ce2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the req. file for docker\n",
    "!pip freeze > /home/jovyan/proj/docker/jupyter-base-ds/requirements.txt\n",
    "!git config --global user.email \"\" \n",
    "!git config --global user.name  \"Menno Witteveen\"\n",
    "!git -C /home/jovyan/proj/docker/jupyter-compbio-ds/ add requirements.txt\n",
    "# !git -C /home/jovyan/proj/docker/jupyter-base-ds/ status\n",
    "!git -C /home/jovyan/proj/docker/jupyter-compbio-ds/ commit -m \"update req.txt with line_profiler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e68d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ff'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7afc5d1",
   "metadata": {},
   "source": [
    "# Base Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f223391f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabf7250",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "########################################################\n",
    "## Base Imports:\n",
    "\n",
    "# Sys Imports:\n",
    "import time, sys, os\n",
    "\n",
    "# Standard Imports:\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats, linalg\n",
    "\n",
    "#########################################################\n",
    "## Experiment Specific Imports\n",
    "\n",
    "# Logistics Imports:\n",
    "import inspect, glob, re, contextlib, pickle, functools #,submitit #pyreadr\n",
    "from tqdm.auto import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "from mjwt.utils import jobinfo, corr, implot, sizegb, psrc, beep, Timer, Struct as mStruct\n",
    "\n",
    "# ML Imports:\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Genomics Imports:\n",
    "import pysnptools as pst\n",
    "from pysnptools.snpreader import Bed, Pheno, SnpHdf5, SnpData\n",
    "from pysnptools.pstreader import PstData, PstHdf5, PstReader\n",
    "from lambdapred.utils import load_bimfam\n",
    "\n",
    "########################################################\n",
    "## Configuration & Initialisation\n",
    "\n",
    "# Display Configuration:\n",
    "from IPython.display import set_matplotlib_formats, display #, HTML, Audio, Javascript\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "pd.set_option('max_colwidth', 200) \n",
    "# pd.set_option('display.max_colwidth', None) # No pd trunkation (radical)\n",
    "# display(HTML(\"<style>.container { width:75% !important; }</style>\"))\n",
    "# pd.reset_option('all')\n",
    "\n",
    "# Initializations & Extensions:\n",
    "timer = Timer(); toc = timer.toc; tic = timer.tic; tic(''); log=np.log10\n",
    "notebook = False  if '__file__' in locals() else True\n",
    "with contextlib.suppress(BaseException): # non-essential import for development.\n",
    "    get_ipython().run_line_magic('load_ext', 'line_profiler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this line if you want to get some help infos:\n",
    "??implot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd1129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f5f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pysnptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8db4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d3ae0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bcbf3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69e848ac",
   "metadata": {},
   "source": [
    "# ML Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78f246c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5114ec75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ecf4cf4",
   "metadata": {},
   "source": [
    "## Pytorch 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dd7f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3237076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# For this example, the output y is a linear function of (x, x^2, x^3), so\n",
    "# we can consider it as a linear layer neural network. Let's prepare the\n",
    "# tensor (x, x^2, x^3).\n",
    "p = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "\n",
    "# In the above code, x.unsqueeze(-1) has shape (2000, 1), and p has shape\n",
    "# (3,), for this case, broadcasting semantics will apply to obtain a tensor\n",
    "# of shape (2000, 3) \n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. The Linear Module computes output from input using a\n",
    "# linear function, and holds internal Tensors for its weight and bias.\n",
    "# The Flatten layer flatens the output of the linear layer to a 1D tensor,\n",
    "# to match the shape of `y`.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3, 1),\n",
    "    torch.nn.Flatten(0, 1)\n",
    ")\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "\n",
    "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
    "    # override the __call__ operator so you can call them like functions. When\n",
    "    # doing so you pass a Tensor of input data to the Module and it produces\n",
    "    # a Tensor of output data.\n",
    "    y_pred = model(xx)\n",
    "\n",
    "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
    "    # values of y, and the loss function returns a Tensor containing the\n",
    "    # loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero the gradients before running the backward pass.\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "    # parameters of the model. Internally, the parameters of each Module are stored\n",
    "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
    "    # all learnable parameters in the model.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
    "    # we can access its gradients like we did before.\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n",
    "\n",
    "# You can access the first layer of `model` like accessing the first item of a list\n",
    "linear_layer = model[0]\n",
    "\n",
    "# For linear layer, its parameters are stored as `weight` and `bias`.\n",
    "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c59087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a4b326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e3410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6397abd6",
   "metadata": {},
   "source": [
    "# Schedulers\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7109a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9f70dae",
   "metadata": {},
   "source": [
    "## Slurm & Submitit Tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d8373e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23811273",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, job in job_dt.items():\n",
    "    job.cancel()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c4f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel ALL submitit jobs!:\n",
    "from io import StringIO\n",
    "string =  !que\n",
    "stringio = StringIO('\\n'.join(string))\n",
    "que_df = pd.read_table(stringio, delim_whitespace=True); que_df\n",
    "\n",
    "for _, jobid in que_df.JOBID[que_df.NAME == 'submitit'].iteritems():\n",
    "    jerg\n",
    "    !scancel {jobid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34532a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"\"\"60080867, 60080868, 60080869, 60080870, 60080871, 60080872, \"\"\"\n",
    "log_folder = \"/home/mennow/dsmwpred/mennow/log_test/%j\"\n",
    "eval_job_dt = dict()\n",
    "for i, job_id in enumerate(string.split(', ')):\n",
    "    if job_id != '': eval_job_dt[i] = submitit.SlurmJob(job_id=job_id, folder=log_folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569ffa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43f272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "string='''{0: SlurmJob<job_id=55037710, task_id=0, state=\"COMPLETED\">,\n",
    " 1: SlurmJob<job_id=55037711, task_id=0, state=\"COMPLETED\">,\n",
    " 2: SlurmJob<job_id=55037712, task_id=0, state=\"RUNNING\">,\n",
    " 3: SlurmJob<job_id=55037713, task_id=0, state=\"RUNNING\">,\n",
    " 4: SlurmJob<job_id=55037714, task_id=0, state=\"COMPLETED\">,\n",
    " 5: SlurmJob<job_id=55037715, task_id=0, state=\"COMPLETED\">,\n",
    " 6: SlurmJob<job_id=55037716, task_id=0, state=\"RUNNING\">,\n",
    " 7: SlurmJob<job_id=55037717, task_id=0, state=\"RUNNING\">,\n",
    " 8: SlurmJob<job_id=55037718, task_id=0, state=\"COMPLETED\">,\n",
    " 9: SlurmJob<job_id=55037719, task_id=0, state=\"COMPLETED\">,\n",
    " 10: SlurmJob<job_id=55037720, task_id=0, state=\"COMPLETED\">,\n",
    " 11: SlurmJob<job_id=55037721, task_id=0, state=\"RUNNING\">,\n",
    " 12: SlurmJob<job_id=55037722, task_id=0, state=\"RUNNING\">,\n",
    " 13: SlurmJob<job_id=55037723, task_id=0, state=\"RUNNING\">,\n",
    " 14: SlurmJob<job_id=55037724, task_id=0, state=\"RUNNING\">,\n",
    " 15: SlurmJob<job_id=55037725, task_id=0, state=\"RUNNING\">}'''\n",
    "\n",
    "folder = \"/home/mennow/dsmwpred/mennow/log_test/%j\"\n",
    "job_dt = dict()\n",
    "for i, elem in enumerate(string.split('\\n')):\n",
    "    start = 'job_id='\n",
    "    stop = ', task_id='\n",
    "    job_id = elem[elem.find(start)+len(start):elem.find(stop)]\n",
    "    job_dt[i] = submitit.SlurmJob(job_id=job_id, folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b35593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98903a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean out everything older then 9 days modded. Careful with this!\n",
    "!find ./log_test/* -type d -ctime +9 -exec rm -rf {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5246c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85553137",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = !squeue -t pd\n",
    "# string = !squeue -t r # For RUNNING ones.\n",
    "string = '\\n'.join(string)\n",
    "from io import StringIO\n",
    "df = pd.read_csv(StringIO(string), delim_whitespace=True)\n",
    "df.groupby('USER').count().sort_values(by='JOBID').iloc[::-1]\n",
    "\n",
    "# If you really want all: this cell is a little buggy...\n",
    "string = !squeue -u mennow\n",
    "string = '\\n'.join(string)--format=\"%all\"\n",
    "from io import StringIO\n",
    "df = pd.read_csv(StringIO(string), delim_whitespace=True)\n",
    "\n",
    "# Seeing some prints:\n",
    "[print(f'---> i={i} <---\\n', job_dt[i].stdout()[-100:]) for i in np.sort(np.random.randint(0,len(job_dt), 4)) if job_dt[i].stdout() is not None]\n",
    "\n",
    "# See a unique count of all the Slurm states:\n",
    "df = pd.DataFrame([elem.state for elem in eval_job_dt.values()])\n",
    "df[1] = 1.\n",
    "df.groupby(0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edb3633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee6218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09311f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d9b533a",
   "metadata": {},
   "source": [
    "# Decoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8797f74e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadec2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daaab008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setter of x called\n",
      "getter of x called\n",
      "deleter of x called\n"
     ]
    }
   ],
   "source": [
    "# Methods that overwrite the getting and setting syntax\n",
    "class C(object):\n",
    "    def __init__(self):\n",
    "        self._x = None\n",
    "        self.data = 42\n",
    "\n",
    "    @property\n",
    "    def x(self):\n",
    "        \"\"\"I'm the 'x' property.\"\"\"\n",
    "        print(\"getter of x called\")\n",
    "        return self._x\n",
    "\n",
    "    @x.setter\n",
    "    def x(self, value):\n",
    "        print(\"setter of x called\")\n",
    "        self._x = value\n",
    "\n",
    "    @x.deleter\n",
    "    def x(self):\n",
    "        print(\"deleter of x called\")\n",
    "        del self._x\n",
    "        \n",
    "\n",
    "c = C()\n",
    "c.x = 'foo'  # setter called\n",
    "foo = c.x    # getter called\n",
    "del c.x      # deleter called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea5a07f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.1px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
