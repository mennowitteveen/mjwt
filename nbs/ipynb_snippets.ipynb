{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92653ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a7c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa95de26",
   "metadata": {},
   "source": [
    "# ipynb_snippets\n",
    "> This notebook & webpage (depending on how you're access it) contains a quick reference for python code to do various things. See the legend on the right to jump to a section.\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff64c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6da4ea43",
   "metadata": {},
   "source": [
    "# Some brief notes:\n",
    "\n",
    "- [Hamel's blog for inspiration](https://hamel.dev/notes/linux/bash_scripting.html)\n",
    "- some person's homepage https://www.mm218.dev/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb10c118",
   "metadata": {},
   "source": [
    "Oke this is a bunch of test text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb6949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94da41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8bb0d3f",
   "metadata": {},
   "source": [
    "# Todo dump:\n",
    "\n",
    "- pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b49a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ce2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the req. file for docker\n",
    "!pip freeze > /home/jovyan/proj/docker/jupyter-base-ds/requirements.txt\n",
    "!git config --global user.email \"\" \n",
    "!git config --global user.name  \"Menno Witteveen\"\n",
    "!git -C /home/jovyan/proj/docker/jupyter-compbio-ds/ add requirements.txt\n",
    "# !git -C /home/jovyan/proj/docker/jupyter-base-ds/ status\n",
    "!git -C /home/jovyan/proj/docker/jupyter-compbio-ds/ commit -m \"update req.txt with line_profiler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e68d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ff'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7afc5d1",
   "metadata": {},
   "source": [
    "# Base Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f223391f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabf7250",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "########################################################\n",
    "## Base Imports:\n",
    "\n",
    "# Sys Imports:\n",
    "import time, sys, os\n",
    "\n",
    "# Standard Imports:\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats, linalg\n",
    "\n",
    "#########################################################\n",
    "## Experiment Specific Imports\n",
    "\n",
    "# Logistics Imports:\n",
    "import inspect, glob, re, contextlib, pickle, functools #,submitit #pyreadr\n",
    "from tqdm.auto import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "from mjwt.utils import jobinfo, corr, implot, sizegb, psrc, beep, Timer, Struct as mStruct\n",
    "\n",
    "# ML Imports:\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Genomics Imports:\n",
    "import pysnptools as pst\n",
    "from pysnptools.snpreader import Bed, Pheno, SnpHdf5, SnpData\n",
    "from pysnptools.pstreader import PstData, PstHdf5, PstReader\n",
    "from lambdapred.utils import load_bimfam\n",
    "\n",
    "########################################################\n",
    "## Configuration & Initialisation\n",
    "\n",
    "# Display Configuration:\n",
    "from IPython.display import set_matplotlib_formats, display #, HTML, Audio, Javascript\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "pd.set_option('max_colwidth', 200) \n",
    "# pd.set_option('display.max_colwidth', None) # No pd trunkation (radical)\n",
    "# display(HTML(\"<style>.container { width:75% !important; }</style>\"))\n",
    "# pd.reset_option('all')\n",
    "\n",
    "# Initializations & Extensions:\n",
    "timer = Timer(); toc = timer.toc; tic = timer.tic; tic(''); log=np.log10\n",
    "notebook = False  if '__file__' in locals() else True\n",
    "with contextlib.suppress(BaseException): # non-essential import for development.\n",
    "    get_ipython().run_line_magic('load_ext', 'line_profiler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this line if you want to get some help infos:\n",
    "??implot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd1129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f5f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pysnptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8db4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d3ae0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62760043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f82768fb",
   "metadata": {},
   "source": [
    "# ML Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e0063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fbadde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23516716",
   "metadata": {},
   "source": [
    "## Pytorch 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adcada6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3237076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# For this example, the output y is a linear function of (x, x^2, x^3), so\n",
    "# we can consider it as a linear layer neural network. Let's prepare the\n",
    "# tensor (x, x^2, x^3).\n",
    "p = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "\n",
    "# In the above code, x.unsqueeze(-1) has shape (2000, 1), and p has shape\n",
    "# (3,), for this case, broadcasting semantics will apply to obtain a tensor\n",
    "# of shape (2000, 3) \n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. The Linear Module computes output from input using a\n",
    "# linear function, and holds internal Tensors for its weight and bias.\n",
    "# The Flatten layer flatens the output of the linear layer to a 1D tensor,\n",
    "# to match the shape of `y`.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3, 1),\n",
    "    torch.nn.Flatten(0, 1)\n",
    ")\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "\n",
    "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
    "    # override the __call__ operator so you can call them like functions. When\n",
    "    # doing so you pass a Tensor of input data to the Module and it produces\n",
    "    # a Tensor of output data.\n",
    "    y_pred = model(xx)\n",
    "\n",
    "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
    "    # values of y, and the loss function returns a Tensor containing the\n",
    "    # loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero the gradients before running the backward pass.\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "    # parameters of the model. Internally, the parameters of each Module are stored\n",
    "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
    "    # all learnable parameters in the model.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
    "    # we can access its gradients like we did before.\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n",
    "\n",
    "# You can access the first layer of `model` like accessing the first item of a list\n",
    "linear_layer = model[0]\n",
    "\n",
    "# For linear layer, its parameters are stored as `weight` and `bias`.\n",
    "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c59087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a4b326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78758603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36a87c2c",
   "metadata": {},
   "source": [
    "# Schedulers:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dda20b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "963c0536",
   "metadata": {},
   "source": [
    "## Slurm & Submitit Tricks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0315cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e31e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, job in job_dt.items():\n",
    "    job.cancel()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d98609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel ALL submitit jobs!:\n",
    "from io import StringIO\n",
    "string =  !que\n",
    "stringio = StringIO('\\n'.join(string))\n",
    "que_df = pd.read_table(stringio, delim_whitespace=True); que_df\n",
    "\n",
    "for _, jobid in que_df.JOBID[que_df.NAME == 'submitit'].iteritems():\n",
    "    jerg\n",
    "    !scancel {jobid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0275af4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcefa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"\"\"60080867, 60080868, 60080869, 60080870, 60080871, 60080872, \"\"\"\n",
    "log_folder = \"/home/mennow/dsmwpred/mennow/log_test/%j\"\n",
    "eval_job_dt = dict()\n",
    "for i, job_id in enumerate(string.split(', ')):\n",
    "    if job_id != '': eval_job_dt[i] = submitit.SlurmJob(job_id=job_id, folder=log_folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b812c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f59287",
   "metadata": {},
   "outputs": [],
   "source": [
    "string='''{0: SlurmJob<job_id=55037710, task_id=0, state=\"COMPLETED\">,\n",
    " 1: SlurmJob<job_id=55037711, task_id=0, state=\"COMPLETED\">,\n",
    " 2: SlurmJob<job_id=55037712, task_id=0, state=\"RUNNING\">,\n",
    " 3: SlurmJob<job_id=55037713, task_id=0, state=\"RUNNING\">,\n",
    " 4: SlurmJob<job_id=55037714, task_id=0, state=\"COMPLETED\">,\n",
    " 5: SlurmJob<job_id=55037715, task_id=0, state=\"COMPLETED\">,\n",
    " 6: SlurmJob<job_id=55037716, task_id=0, state=\"RUNNING\">,\n",
    " 7: SlurmJob<job_id=55037717, task_id=0, state=\"RUNNING\">,\n",
    " 8: SlurmJob<job_id=55037718, task_id=0, state=\"COMPLETED\">,\n",
    " 9: SlurmJob<job_id=55037719, task_id=0, state=\"COMPLETED\">,\n",
    " 10: SlurmJob<job_id=55037720, task_id=0, state=\"COMPLETED\">,\n",
    " 11: SlurmJob<job_id=55037721, task_id=0, state=\"RUNNING\">,\n",
    " 12: SlurmJob<job_id=55037722, task_id=0, state=\"RUNNING\">,\n",
    " 13: SlurmJob<job_id=55037723, task_id=0, state=\"RUNNING\">,\n",
    " 14: SlurmJob<job_id=55037724, task_id=0, state=\"RUNNING\">,\n",
    " 15: SlurmJob<job_id=55037725, task_id=0, state=\"RUNNING\">}'''\n",
    "\n",
    "folder = \"/home/mennow/dsmwpred/mennow/log_test/%j\"\n",
    "job_dt = dict()\n",
    "for i, elem in enumerate(string.split('\\n')):\n",
    "    start = 'job_id='\n",
    "    stop = ', task_id='\n",
    "    job_id = elem[elem.find(start)+len(start):elem.find(stop)]\n",
    "    job_dt[i] = submitit.SlurmJob(job_id=job_id, folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f72b2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548d01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean out everything older then 9 days modded. Careful with this!\n",
    "!find ./log_test/* -type d -ctime +9 -exec rm -rf {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39500f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee11574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b09300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d9d197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04695e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "134c3037",
   "metadata": {},
   "source": [
    "# Decoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883d9cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadec2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe53ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setter of x called\n",
      "getter of x called\n",
      "deleter of x called\n"
     ]
    }
   ],
   "source": [
    "# Methods that overwrite the getting and setting syntax\n",
    "class C(object):\n",
    "    def __init__(self):\n",
    "        self._x = None\n",
    "        self.data = 42\n",
    "\n",
    "    @property\n",
    "    def x(self):\n",
    "        \"\"\"I'm the 'x' property.\"\"\"\n",
    "        print(\"getter of x called\")\n",
    "        return self._x\n",
    "\n",
    "    @x.setter\n",
    "    def x(self, value):\n",
    "        print(\"setter of x called\")\n",
    "        self._x = value\n",
    "\n",
    "    @x.deleter\n",
    "    def x(self):\n",
    "        print(\"deleter of x called\")\n",
    "        del self._x\n",
    "        \n",
    "\n",
    "c = C()\n",
    "c.x = 'foo'  # setter called\n",
    "foo = c.x    # getter called\n",
    "del c.x      # deleter called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83312923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
